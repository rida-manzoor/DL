{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAw1fXu50f4OBczbhogag3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rida-manzoor/DL/blob/main/17_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agenda of this Notebook\n",
        "1. Why we can't train our own model?\n",
        "2. What is transfer Learning?\n",
        "3. Problem with pre-trained models.\n",
        "4. Why transfer learning works?"
      ],
      "metadata": {
        "id": "oTZp_tA6eoe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why we can't train our own model?\n",
        "1. Neural Network are data hungary\n",
        "2. Computation costs\n",
        "3. Data labelling is an issue.\n",
        "\n",
        "\n",
        "## Problem with pre-trained models\n",
        "- **Generalization Limitations:** Pre-trained models may not generalize well to specific or niche domains.\n",
        "\n",
        "- **Biases:** Models can inherit biases from the data they were trained on, leading to biased outputs.\n",
        "\n",
        "- **Lack of Domain Knowledge:** Models lack domain-specific knowledge and may not perform optimally in specialized fields.\n",
        "\n",
        "- **Overfitting to Training Data:** Models might overfit to biases present in the training data, limiting adaptability to new contexts.\n",
        "\n",
        "- **Computational Resources:** Fine-tuning or adapting large pre-trained models requires substantial computational resources.\n",
        "\n",
        "# Transfer Learning\n",
        "Transfer learning is a machine learning technique where a model trained on one task is adapted for a related but different task. Instead of training a model from scratch for a new task, transfer learning leverages knowledge gained from solving one problem to improve performance on another. There are two main types of transfer learning:\n",
        "\n",
        "1. **Feature-based Transfer Learning:** The pre-trained model's lower layers (features) are used as a generic feature extractor for the new task. The higher layers are then retrained for the specific task. Used for task in which labels are kind of similar to data on which model is already trained.\n",
        "\n",
        "2. **Fine-tuning:** The entire pre-trained model is further trained on the new task, adjusting weights across all layers to adapt to the specific domain. Used for tasks whose labels are different from data labels on which model is trained.\n",
        "\n",
        "Transfer learning is particularly useful when the amount of labeled data for the target task is limited, as it enables the model to leverage knowledge gained from larger datasets in related domains."
      ],
      "metadata": {
        "id": "V0BDbgSne6fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why transfer learning work?\n",
        "- Early layers only extract primitive features(Edges). And last layer classify image. So Early layer task are generic and will work same for every image. That's why we don't replace them."
      ],
      "metadata": {
        "id": "uT2o-Id2XC0K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-IU2GuvYz4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}