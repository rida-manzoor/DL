{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSwZVRO7z/Z2Vhrs8DOMVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rida-manzoor/DL/blob/main/26_Attention_Mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Mechanism\n",
        "\n",
        "Why we need attention mechanism?\n",
        "\n",
        "1. Encoder first read whole sentence and then generate a summary. If the sentence is long,like paragraph, remembering whole sentence is kinda difficult. Thats mean we are creating unneccessary pressure on encode to do so. This is the first problem with encoder decoder.\n",
        "2. In decoder part, at given timestep we don't need whole sentence to translate particular word/token. Because of this statis representation decoder face problem to decode.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "We have to introduce attention space in decoder. At a particular time step we need to tell decoder that this timestep from encoder is most important to translate given timestep.\n",
        "\n",
        "![ds](https://miro.medium.com/v2/resize:fit:640/format:webp/1*We87td0yKdnI_pDGkyvS1g.png)\n",
        "\n",
        "c_i is vector and dimension is exactly same as h_i. But if we have to give more than one hidden state we will give weighted average.\n",
        "\n",
        "$$c_1 = α_1h_1+α_2h_2+α_ih_i  $$\n",
        "$$c_2 = α_1h_1+α_2h_2+α_ih_i  $$\n",
        "$$c_3 = α_1h_1+α_2h_2+α_ih_i  $$\n",
        "$$c_i=Σα_ijh_i $$\n",
        "\n",
        " alpha_21 is the similarity score that tells at decoder 2 timestep, what role encoder 1 timestep have. And it depends on h_1 and s_1(which is previous hidden state of decoder)\n",
        "\n",
        " $$α_ij=f(h_j,s_i-1)  $$\n",
        "\n",
        " Now what function is more suitable for approximation???\n",
        "\n",
        " Here researcher use ANN as function. As ANN is universal function approximator if provided enough data. So there is a dense neural network whose input is h_i and s_i & will give alpha as output.\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "-Onz5TSMp3Kz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1Yhsgizow-E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "* https://distill.pub/2016/augmented-rnns/\n",
        "* https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc"
      ],
      "metadata": {
        "id": "2t_CPfLdzZbs"
      }
    }
  ]
}